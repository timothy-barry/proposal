% $ biblatex auxiliary file $
% $ biblatex bbl format version 2.9 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{nyt/global//global/global}
    \entry{Barber2015}{article}{}
      \name{author}{2}{}{%
        {{uniquename=0,uniquepart=base,hash=826fc96de04a5307c256bfb0b6202e0f}{%
           family={Barber},
           familyi={B\bibinitperiod},
           given={Rina\bibnamedelima Foygel},
           giveni={R\bibinitperiod\bibinitdelim F\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=a9a5219f71b7e2464ef1ebc541e54f1f}{%
           family={Cand{é}s},
           familyi={C\bibinitperiod},
           given={Emmanuel\bibnamedelima J.},
           giveni={E\bibinitperiod\bibinitdelim J\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{ab29a92420006b6d62ee2935caeb1eb4}
      \strng{fullhash}{ab29a92420006b6d62ee2935caeb1eb4}
      \strng{bibnamehash}{ab29a92420006b6d62ee2935caeb1eb4}
      \strng{authorbibnamehash}{ab29a92420006b6d62ee2935caeb1eb4}
      \strng{authornamehash}{ab29a92420006b6d62ee2935caeb1eb4}
      \strng{authorfullhash}{ab29a92420006b6d62ee2935caeb1eb4}
      \field{sortinit}{B}
      \field{sortinithash}{276475738cc058478c1677046f857703}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In many fields of science, we observe a response variable together with a large number of potential explanatory variables, and would like to be able to discover which variables are truly associated with the response. At the same time, we need to know that the false discovery rate (FDR)the expected fraction of false discoveries among all discoveriesis not too high, in order to assure the scientist that most of the discoveries are indeed true and replicable. This paper introduces the knockoff filter, a new variable selection procedure controlling the FDR in the statistical linear model whenever there are at least as many observations as variables. This method achieves exact FDR control in finite sample settings no matter the design or covariates, the number of variables in the model, or the amplitudes of the unknown regression coefficients, and does not require any knowledge of the noise level. As the name suggests, the method operates by manufacturing knockoff variables that are cheaptheir construction does not require any new dataand are designed to mimic the correlation structure found within the existing variables, in a way that allows for accurate FDR control, beyond what is possible with permutation-based methods. The method of knockoffs is very general and flexible, and can work with a broad class of test statistics. We test the method in combination with statistics from the Lasso for sparse regression, and obtain empirical results showing that the resulting method has far more power than existing selection rules when the proportion of null variables is high.}
      \field{eprinttype}{arXiv}
      \field{issn}{21688966}
      \field{journaltitle}{Annals of Statistics}
      \field{number}{5}
      \field{title}{{Controlling the false discovery rate via knockoffs}}
      \field{volume}{43}
      \field{year}{2015}
      \field{pages}{2055\bibrangedash 2085}
      \range{pages}{31}
      \verb{doi}
      \verb 10.1214/15-AOS1337
      \endverb
      \verb{eprint}
      \verb 1404.5609
      \endverb
      \verb{file}
      \verb :Users/timbarry/research{\_}papers/barber2015.pdf:pdf
      \endverb
      \keyw{False discovery rate (FDR),Lasso,Martingale theory,Permutation methods,Sequential hypothesis testing,Variable selection}
    \endentry
    \entry{Berrett2020}{article}{}
      \name{author}{4}{}{%
        {{uniquename=0,uniquepart=base,hash=da2225ed6f5194fdb7864fb6918e5562}{%
           family={Berrett},
           familyi={B\bibinitperiod},
           given={Thomas\bibnamedelima B.},
           giveni={T\bibinitperiod\bibinitdelim B\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=141a1e7404c5b53546fb09821c56717a}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Yi},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=826fc96de04a5307c256bfb0b6202e0f}{%
           family={Barber},
           familyi={B\bibinitperiod},
           given={Rina\bibnamedelima Foygel},
           giveni={R\bibinitperiod\bibinitdelim F\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=f571f0f9e4636dc38784d87fb2be633a}{%
           family={Samworth},
           familyi={S\bibinitperiod},
           given={Richard\bibnamedelima J.},
           giveni={R\bibinitperiod\bibinitdelim J\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{6551256fb2bcc96d56687bf81cf43fb7}
      \strng{fullhash}{b075a5ce38df23884ab4041806a9b299}
      \strng{bibnamehash}{b075a5ce38df23884ab4041806a9b299}
      \strng{authorbibnamehash}{b075a5ce38df23884ab4041806a9b299}
      \strng{authornamehash}{6551256fb2bcc96d56687bf81cf43fb7}
      \strng{authorfullhash}{b075a5ce38df23884ab4041806a9b299}
      \field{sortinit}{B}
      \field{sortinithash}{276475738cc058478c1677046f857703}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose a general new method, the conditional permutation test, for testing the conditional independence of variables X and Y given a potentially high dimensional random vector Z that may contain confounding factors. The test permutes entries of X non-uniformly, to respect the existing dependence between X and Z and thus to account for the presence of these confounders. Like the conditional randomization test of Cand{è}s and co-workers in 2018, our test relies on the availability of an approximation to the distribution of X|Z—whereas their test uses this estimate to draw new X-values, for our test we use this approximation to design an appropriate non-uniform distribution on permutations of the X-values already seen in the true data. We provide an efficient Markov chain Monte Carlo sampler for the implementation of our method and establish bounds on the type I error in terms of the error in the approximation of the conditional distribution of X|Z, finding that, for the worst-case test statistic, the inflation in type I error of the conditional permutation test is no larger than that of the conditional randomization test. We validate these theoretical results with experiments on simulated data and on the Capital Bikeshare data set.}
      \field{eprinttype}{arXiv}
      \field{issn}{14679868}
      \field{journaltitle}{Journal of the Royal Statistical Society. Series B: Statistical Methodology}
      \field{number}{1}
      \field{title}{{The conditional permutation test for independence while controlling for confounders}}
      \field{volume}{82}
      \field{year}{2020}
      \field{pages}{175\bibrangedash 197}
      \range{pages}{23}
      \verb{doi}
      \verb 10.1111/rssb.12340
      \endverb
      \verb{eprint}
      \verb 1807.05405
      \endverb
      \verb{file}
      \verb :Users/timbarry/Library/Application Support/Mendeley Desktop/Downloaded/Berrett et al. - 2020 - The conditional permutation test for independence while controlling for confounders.pdf:pdf
      \endverb
      \keyw{Conditional independence testing,Exchangeability,Model misspecification,Model-X knockoffs,Permutation tests,Semisupervised learning,statistics}
    \endentry
    \entry{Chernozhukov2018}{article}{}
      \name{author}{7}{}{%
        {{uniquename=0,uniquepart=base,hash=c75cbe2cefd1e532f636a50892605d06}{%
           family={Chernozhukov},
           familyi={C\bibinitperiod},
           given={Victor},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=ef4b66d2ca2dde47ec1b0afa98306775}{%
           family={Chetverikov},
           familyi={C\bibinitperiod},
           given={Denis},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=d3c2cc443c71254678269de10d61d61c}{%
           family={Demirer},
           familyi={D\bibinitperiod},
           given={Mert},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=7e6b0ea4eee38822cdb0a4361e98752c}{%
           family={Duflo},
           familyi={D\bibinitperiod},
           given={Esther},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=b38b53cdfa3ce5b62046f22663d5cc6f}{%
           family={Hansen},
           familyi={H\bibinitperiod},
           given={Christian},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=9c98526d9f1775b95096664c9cf0c633}{%
           family={Newey},
           familyi={N\bibinitperiod},
           given={Whitney},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=bf615cc72310078c444f0c653a1fc5e7}{%
           family={Robins},
           familyi={R\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{e8ad45c8076487daa445bfbeb4e02a04}
      \strng{fullhash}{7892f5fdea2b46a0fb4e6c031c27c781}
      \strng{bibnamehash}{e8ad45c8076487daa445bfbeb4e02a04}
      \strng{authorbibnamehash}{e8ad45c8076487daa445bfbeb4e02a04}
      \strng{authornamehash}{e8ad45c8076487daa445bfbeb4e02a04}
      \strng{authorfullhash}{7892f5fdea2b46a0fb4e6c031c27c781}
      \field{sortinit}{C}
      \field{sortinithash}{963e9d84a3da2344e8833203de5aed05}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We revisit the classic semi-parametric problem of inference on a low-dimensional parameter $\theta$0 in the presence of high-dimensional nuisance parameters $\eta$0. We depart from the classical setting by allowing for $\eta$0 to be so high-dimensional that the traditional assumptions (e.g. Donsker properties) that limit complexity of the parameter space for this object break down. To estimate $\eta$0, we consider the use of statistical or machine learning (ML) methods, which are particularly well suited to estimation in modern, very high-dimensional cases. ML methods perform well by employing regularization to reduce variance and trading off regularization bias with overfitting in practice. However, both regularization bias and overfitting in estimating $\eta$0 cause a heavy bias in estimators of $\theta$0 that are obtained by naively plugging ML estimators of $\eta$0 into estimating equations for $\theta$0. This bias results in the naive estimator failing to be N-1/2 consistent, where N is the sample size. We show that the impact of regularization bias and overfitting on estimation of the parameter of interest $\theta$0 can be removed by using two simple, yet critical, ingredients: (1) using Neyman-orthogonal moments/scores that have reduced sensitivity with respect to nuisance parameters to estimate $\theta$0; (2) making use of cross-fitting, which provides an efficient form of data-splitting. We call the resulting set of methods double or debiased ML (DML). We verify that DML delivers point estimators that concentrate in an N-1 -neighbourhood of the true parameter values and are approximately unbiased and normally distributed, which allows construction of valid confidence statements. The generic statistical theory of DML is elementary and simultaneously relies on only weak theoretical requirements, which will admit the use of a broad array of modern ML methods for estimating the nuisance parameters, such as random forests, lasso, ridge, deep neural nets, boosted trees, and various hybrids and ensembles of these methods. We illustrate the general theory by applying it to provide theoretical properties of the following: DML applied to learn the main regression parameter in a partially linear regression model; DML applied to learn the coefficient on an endogenous variable in a partially linear instrumental variables model; DML applied to learn the average treatment effect and the average treatment effect on the treated under unconfoundedness; DML applied to learn the local average treatment effect in an instrumental variables setting. In addition to these theoretical applications, we also illustrate the use of DML in three empirical examples.}
      \field{issn}{1368423X}
      \field{journaltitle}{Econometrics Journal}
      \field{number}{1}
      \field{title}{{Double/debiased machine learning for treatment and structural parameters}}
      \field{volume}{21}
      \field{year}{2018}
      \field{pages}{C1\bibrangedash C68}
      \range{pages}{-1}
      \verb{doi}
      \verb 10.1111/ectj.12097
      \endverb
      \verb{file}
      \verb :Users/timbarry/research{\_}papers/dml.pdf:pdf
      \endverb
    \endentry
    \entry{Johnson2010}{article}{}
      \name{author}{7}{}{%
        {{uniquename=0,uniquepart=base,hash=db3477bb4c2e3d13bb9241d7c07f3fb5}{%
           family={Johnson},
           familyi={J\bibinitperiod},
           given={Randall\bibnamedelima C.},
           giveni={R\bibinitperiod\bibinitdelim C\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=6ab74bfc89b00e35838bdafbadb1cd21}{%
           family={Nelson},
           familyi={N\bibinitperiod},
           given={George\bibnamedelima W.},
           giveni={G\bibinitperiod\bibinitdelim W\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=210d7530673235fd3c759efae2e8e1af}{%
           family={Troyer},
           familyi={T\bibinitperiod},
           given={Jennifer\bibnamedelima L.},
           giveni={J\bibinitperiod\bibinitdelim L\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=fc681caaec7db0d732febe02301c0afc}{%
           family={Lautenberger},
           familyi={L\bibinitperiod},
           given={James\bibnamedelima A.},
           giveni={J\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=e3b5bc18c5c3274b89f8f80a2d8317c9}{%
           family={Kessing},
           familyi={K\bibinitperiod},
           given={Bailey\bibnamedelima D.},
           giveni={B\bibinitperiod\bibinitdelim D\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=f9a573773dc7e1bb516bba6b750909d9}{%
           family={Winkler},
           familyi={W\bibinitperiod},
           given={Cheryl\bibnamedelima A.},
           giveni={C\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=0c796739bad1bacabb1a055b32bc2e37}{%
           family={O'Brien},
           familyi={O\bibinitperiod},
           given={Stephen\bibnamedelima J.},
           giveni={S\bibinitperiod\bibinitdelim J\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{eb7350ca84a44283aa35812830f7db18}
      \strng{fullhash}{502d565bb560c8102fad1cff88ffe684}
      \strng{bibnamehash}{eb7350ca84a44283aa35812830f7db18}
      \strng{authorbibnamehash}{eb7350ca84a44283aa35812830f7db18}
      \strng{authornamehash}{eb7350ca84a44283aa35812830f7db18}
      \strng{authorfullhash}{502d565bb560c8102fad1cff88ffe684}
      \field{sortinit}{J}
      \field{sortinithash}{fce5f8d0bd05e8d93f3dbe21c78897ca}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Background: As we enter an era when testing millions of SNPs in a single gene association study will become the standard, consideration of multiple comparisons is an essential part of determining statistical significance. Bonferroni adjustments can be made but are conservative due to the preponderance of linkage disequilibrium (LD) between genetic markers, and permutation testing is not always a viable option. Three major classes of corrections have been proposed to correct the dependent nature of genetic data in Bonferroni adjustments: permutation testing and related alternatives, principal components analysis (PCA), and analysis of blocks of LD across the genome. We consider seven implementations of these commonly used methods using data from 1514 European American participants genotyped for 700,078 SNPs in a GWAS for AIDS.Results: A Bonferroni correction using the number of LD blocks found by the three algorithms implemented by Haploview resulted in an insufficiently conservative threshold, corresponding to a genome-wide significance level of $\alpha$ = 0.15 - 0.20. We observed a moderate increase in power when using PRESTO, SLIDE, and simpleℳ when compared with traditional Bonferroni methods for population data genotyped on the Affymetrix 6.0 platform in European Americans ($\alpha$ = 0.05 thresholds between 1 × 10-7and 7 × 10-8).Conclusions: Correcting for the number of LD blocks resulted in an anti-conservative Bonferroni adjustment. SLIDE and simpleℳ are particularly useful when using a statistical test not handled in optimized permutation testing packages, and genome-wide corrected p-values using SLIDE, are much easier to interpret for consumers of GWAS studies. {©} 2010 Johnson et al; licensee BioMed Central Ltd.}
      \field{issn}{14712164}
      \field{journaltitle}{BMC Genomics}
      \field{number}{1}
      \field{title}{{Accounting for multiple comparisons in a genome-wide association study (GWAS)}}
      \field{volume}{11}
      \field{year}{2010}
      \field{pages}{2\bibrangedash 7}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1186/1471-2164-11-724
      \endverb
      \verb{file}
      \verb :Users/timbarry/research{\_}papers/Johnson2010.pdf:pdf
      \endverb
    \endentry
    \entry{Kim2021}{article}{}
      \name{author}{4}{}{%
        {{uniquename=0,uniquepart=base,hash=c9cba545a9bc42e4e5d7b3729405b106}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Ilmun},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=212c3c3b0ca468d7380aba329711b584}{%
           family={Neykkov},
           familyi={N\bibinitperiod},
           given={Matey},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=3c8c7cdc21150ce96c803d9ce83c36ba}{%
           family={Balakrishnan},
           familyi={B\bibinitperiod},
           given={Sivaraman},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=6b27f4592197d058b81cb25b0b285942}{%
           family={Wasserman},
           familyi={W\bibinitperiod},
           given={Larry},
           giveni={L\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{ba62f90449723d499badce6c4d213d5f}
      \strng{fullhash}{0e05a3ed12b0f16b45c53a628f65c72c}
      \strng{bibnamehash}{0e05a3ed12b0f16b45c53a628f65c72c}
      \strng{authorbibnamehash}{0e05a3ed12b0f16b45c53a628f65c72c}
      \strng{authornamehash}{ba62f90449723d499badce6c4d213d5f}
      \strng{authorfullhash}{0e05a3ed12b0f16b45c53a628f65c72c}
      \field{sortinit}{K}
      \field{sortinithash}{9fd838a31ba64d981e8f44562bd33f89}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{eprinttype}{arXiv}
      \field{title}{{Local permutation tests for conditional independence}}
      \field{year}{2021}
      \verb{eprint}
      \verb arXiv:2112.11666v1
      \endverb
      \verb{file}
      \verb :Users/timbarry/research{\_}papers/kim2021.pdf:pdf
      \endverb
    \endentry
    \entry{Kuchibhotla2020}{article}{}
      \name{author}{1}{}{%
        {{uniquename=0,uniquepart=base,hash=b1a5eb02af8879e0faf4e2346d6d0a69}{%
           family={Kuchibhotla},
           familyi={K\bibinitperiod},
           given={Arun\bibnamedelima Kumar},
           giveni={A\bibinitperiod\bibinitdelim K\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{b1a5eb02af8879e0faf4e2346d6d0a69}
      \strng{fullhash}{b1a5eb02af8879e0faf4e2346d6d0a69}
      \strng{bibnamehash}{b1a5eb02af8879e0faf4e2346d6d0a69}
      \strng{authorbibnamehash}{b1a5eb02af8879e0faf4e2346d6d0a69}
      \strng{authornamehash}{b1a5eb02af8879e0faf4e2346d6d0a69}
      \strng{authorfullhash}{b1a5eb02af8879e0faf4e2346d6d0a69}
      \field{sortinit}{K}
      \field{sortinithash}{9fd838a31ba64d981e8f44562bd33f89}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Conformal prediction has been a very popular method of distribution-free predictive inference in recent years in machine learning and statistics. Its popularity stems from the fact that it works as a wrapper around any prediction algorithm such as neural networks or random forests. Exchangeability is at the core of the validity of conformal prediction. The concept of exchangeability is also at the core of rank tests widely known in nonparametric statistics. In this paper, we review the concept of exchangeability and discuss the implications for conformal prediction and rank tests. We provide a low-level introduction to these topics, and discuss the similarities between conformal prediction and rank tests.}
      \field{eprinttype}{arXiv}
      \field{issn}{2331-8422}
      \field{title}{{Exchangeability, Conformal Prediction, and Rank Tests}}
      \field{year}{2020}
      \field{pages}{1\bibrangedash 36}
      \range{pages}{36}
      \verb{eprint}
      \verb 2005.06095
      \endverb
      \verb{file}
      \verb :Users/timbarry/research{\_}papers/arun{\_}2021{\_}exchangeability.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2005.06095
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2005.06095
      \endverb
    \endentry
    \entry{Li2021}{article}{}
      \name{author}{2}{}{%
        {{uniquename=0,uniquepart=base,hash=39c12931ce1d8a7259be450b9b698526}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Shuangning},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=47e52e423450f79070607f61a9f53828}{%
           family={Cand{è}s},
           familyi={C\bibinitperiod},
           given={Emmanuel\bibnamedelima J.},
           giveni={E\bibinitperiod\bibinitdelim J\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{7d372cb07f9db27e5e042fea0fcf1c68}
      \strng{fullhash}{7d372cb07f9db27e5e042fea0fcf1c68}
      \strng{bibnamehash}{7d372cb07f9db27e5e042fea0fcf1c68}
      \strng{authorbibnamehash}{7d372cb07f9db27e5e042fea0fcf1c68}
      \strng{authornamehash}{7d372cb07f9db27e5e042fea0fcf1c68}
      \strng{authorfullhash}{7d372cb07f9db27e5e042fea0fcf1c68}
      \field{sortinit}{L}
      \field{sortinithash}{2c7981aaabc885868aba60f0c09ee20f}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper introduces the sequential CRT, which is a variable selection procedure that combines the conditional randomization test (CRT) and Selective SeqStep+. Valid p-values are constructed via the flexible CRT, which are then ordered and passed through the selective SeqStep+ filter to produce a list of discoveries. We develop theory guaranteeing control on the false discovery rate (FDR) even though the p-values are not independent. We show in simulations that our novel procedure indeed controls the FDR and are competitive with -- and sometimes outperform -- state-of-the-art alternatives in terms of power. Finally, we apply our methodology to a breast cancer dataset with the goal of identifying biomarkers associated with cancer stage.}
      \field{eprinttype}{arXiv}
      \field{title}{{Deploying the Conditional Randomization Test in High Multiplicity Problems}}
      \field{year}{2021}
      \field{pages}{1\bibrangedash 43}
      \range{pages}{43}
      \verb{eprint}
      \verb 2110.02422
      \endverb
      \verb{file}
      \verb :Users/timbarry/research{\_}papers/Li2021.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2110.02422
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2110.02422
      \endverb
    \endentry
    \entry{Maleki2020}{article}{}
      \name{author}{4}{}{%
        {{uniquename=0,uniquepart=base,hash=590026dd4c91c59cd24c35aeb601eda7}{%
           family={Maleki},
           familyi={M\bibinitperiod},
           given={Farhad},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=ade5924165f48cc54aef374cdb48d6ea}{%
           family={Ovens},
           familyi={O\bibinitperiod},
           given={Katie},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=eaec047beaf43b7eff83347a00f733ab}{%
           family={Hogan},
           familyi={H\bibinitperiod},
           given={Daniel\bibnamedelima J.},
           giveni={D\bibinitperiod\bibinitdelim J\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=c48298a6383576eb43b358a228074dfb}{%
           family={Kusalik},
           familyi={K\bibinitperiod},
           given={Anthony\bibnamedelima J.},
           giveni={A\bibinitperiod\bibinitdelim J\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{b18837cca62c7a809b53e58604f4dd86}
      \strng{fullhash}{365e766ffc6191523dba46992fe63097}
      \strng{bibnamehash}{365e766ffc6191523dba46992fe63097}
      \strng{authorbibnamehash}{365e766ffc6191523dba46992fe63097}
      \strng{authornamehash}{b18837cca62c7a809b53e58604f4dd86}
      \strng{authorfullhash}{365e766ffc6191523dba46992fe63097}
      \field{sortinit}{M}
      \field{sortinithash}{cfd219b90152c06204fab207bc6c7cab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Gene set analysis methods are widely used to provide insight into high-throughput gene expression data. There are many gene set analysis methods available. These methods rely on various assumptions and have different requirements, strengths and weaknesses. In this paper, we classify gene set analysis methods based on their components, describe the underlying requirements and assumptions for each class, and provide directions for future research in developing and evaluating gene set analysis methods.}
      \field{issn}{16648021}
      \field{journaltitle}{Frontiers in Genetics}
      \field{number}{June}
      \field{title}{{Gene Set Analysis: Challenges, Opportunities, and Future Research}}
      \field{volume}{11}
      \field{year}{2020}
      \field{pages}{1\bibrangedash 16}
      \range{pages}{16}
      \verb{doi}
      \verb 10.3389/fgene.2020.00654
      \endverb
      \verb{file}
      \verb :Users/timbarry/research{\_}papers/gene{\_}set{\_}analysis{\_}2020.pdf:pdf
      \endverb
      \keyw{gene expression,gene set analysis,gene set database,gene set enrichment,sensitivity,specificity}
    \endentry
    \entry{Shah2020}{article}{}
      \name{author}{2}{}{%
        {{uniquename=0,uniquepart=base,hash=6b2da2d11d2ab28853c86f9da5ac8803}{%
           family={Shah},
           familyi={S\bibinitperiod},
           given={Rajen\bibnamedelima D.},
           giveni={R\bibinitperiod\bibinitdelim D\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=b50a0fee091540dedaefacc234101037}{%
           family={Peters},
           familyi={P\bibinitperiod},
           given={Jonas},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{8e464cad6c499e26476be2f48afd0f91}
      \strng{fullhash}{8e464cad6c499e26476be2f48afd0f91}
      \strng{bibnamehash}{8e464cad6c499e26476be2f48afd0f91}
      \strng{authorbibnamehash}{8e464cad6c499e26476be2f48afd0f91}
      \strng{authornamehash}{8e464cad6c499e26476be2f48afd0f91}
      \strng{authorfullhash}{8e464cad6c499e26476be2f48afd0f91}
      \field{sortinit}{S}
      \field{sortinithash}{322b1d5276f2f6c1bccdcd15920dbee6}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{It is a common saying that testing for conditional independence, that is, testing whether whether two random vectors X and Y are independent, given Z, is a hard statistical problem if Z is a continuous random variable (or vector). In this paper, we prove that conditional independence is indeed a particularly difficult hypothesis to test for. Valid statistical tests are required to have a size that is smaller than a pre-defined significance level, and different tests usually have power against a different class of alternatives. We prove that a valid test for conditional independence does not have power against any alternative. Given the nonexistence of a uniformly valid conditional independence test, we argue that tests must be designed so their suitability for a particular problem may be judged easily. To address this need, we propose in the case where X and Y are univariate to nonlinearly regress X on Z, and Y on Z and then compute a test statistic based on the sample covariance between the residuals, which we call the generalised covariance measure (GCM). We prove that validity of this form of test relies almost entirely on the weak requirement that the regression procedures are able to estimate the conditional means X given Z, and Y given Z, at a slow rate. We extend the methodology to handle settings where X and Y may be multivariate or even high dimensional. While our general procedure can be tailored to the setting at hand by combining it with any regression technique, we develop the theoretical guarantees for kernel ridge regression. A simulation study shows that the test based on GCM is competitive with state of the art conditional independence tests. Code is available as the R package GeneralisedCovarianceMeasure on CRAN.}
      \field{eprinttype}{arXiv}
      \field{issn}{21688966}
      \field{journaltitle}{Annals of Statistics}
      \field{number}{3}
      \field{title}{{The hardness of conditional independence testing and the generalised covariance measure}}
      \field{volume}{48}
      \field{year}{2020}
      \field{pages}{1514\bibrangedash 1538}
      \range{pages}{25}
      \verb{doi}
      \verb 10.1214/19-AOS1857
      \endverb
      \verb{eprint}
      \verb 1804.07203
      \endverb
      \verb{file}
      \verb :Users/timbarry/research{\_}papers/shah2018.pdf:pdf
      \endverb
      \keyw{Conditional independence,Hypothesis testing,Kernel ridge regression,Testability,Wild bootstrap}
    \endentry
    \entry{Tansey2021a}{article}{}
      \name{author}{5}{}{%
        {{uniquename=0,uniquepart=base,hash=11fdab9d3dd2445509156296b3caa442}{%
           family={Tansey},
           familyi={T\bibinitperiod},
           given={Wesley},
           giveni={W\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=30db2f42d0dd8cf10ef82c5eae10096e}{%
           family={Veitch},
           familyi={V\bibinitperiod},
           given={Victor},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=7d602c606bbdac9b7503677f466b90bc}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Haoran},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=b9758d46819149f72006ed88824cf06d}{%
           family={Rabadan},
           familyi={R\bibinitperiod},
           given={Raul},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=7441e4d372e854fc6d24d0d5a16a1687}{%
           family={Blei},
           familyi={B\bibinitperiod},
           given={David\bibnamedelima M.},
           giveni={D\bibinitperiod\bibinitdelim M\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{32492e1f1cf15dc761a936bb5233ac3d}
      \strng{fullhash}{4bae8dd0d5cb62848186ea3593a0d60a}
      \strng{bibnamehash}{4bae8dd0d5cb62848186ea3593a0d60a}
      \strng{authorbibnamehash}{4bae8dd0d5cb62848186ea3593a0d60a}
      \strng{authornamehash}{32492e1f1cf15dc761a936bb5233ac3d}
      \strng{authorfullhash}{4bae8dd0d5cb62848186ea3593a0d60a}
      \field{sortinit}{T}
      \field{sortinithash}{6f7aff9db9dcfeb7f95fd5bbd2f78df9}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose the holdout randomization test (HRT), an approach to feature selection using black box predictivemodels. TheHRT is a specializedversion of theconditional randomization test (CRT) that usesdata splitting for feasible computation. The HRT works with any predictive model and produces a valid p-value for each feature. To make the HRT more practical, we propose a set of extensions to maximize power and speed up computation. In simulations, these extensions lead to greater power than a competing knockoffs- based approach, without sacrificing control of the error rate. We apply the HRT to two case studies from the scientific literature where heuristics were originally used to select important features for predictive models. The results illustratehowsuchheuristics canbe misleading relative to principled methods like theHRT. Code is available at https://github.com/tansey/hrt. Supplementary materials for this article are available online.}
      \field{journaltitle}{Journal of Computational and Graphical Statistics}
      \field{title}{{The Holdout Randomization Test for Feature Selection in Black Box Models Wesley}}
      \field{year}{2021}
      \field{pages}{1\bibrangedash 12}
      \range{pages}{12}
      \verb{file}
      \verb :Users/timbarry/research{\_}papers/hrt{\_}2021.pdf:pdf
      \endverb
    \endentry
    \entry{Vovk2020}{article}{}
      \name{author}{1}{}{%
        {{uniquename=0,uniquepart=base,hash=bef6907ff5daebb69843cf35c8af1a83}{%
           family={Vovk},
           familyi={V\bibinitperiod},
           given={Vladimir},
           giveni={V\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{bef6907ff5daebb69843cf35c8af1a83}
      \strng{fullhash}{bef6907ff5daebb69843cf35c8af1a83}
      \strng{bibnamehash}{bef6907ff5daebb69843cf35c8af1a83}
      \strng{authorbibnamehash}{bef6907ff5daebb69843cf35c8af1a83}
      \strng{authornamehash}{bef6907ff5daebb69843cf35c8af1a83}
      \strng{authorfullhash}{bef6907ff5daebb69843cf35c8af1a83}
      \field{sortinit}{V}
      \field{sortinithash}{75dd7385c90b2252c3ae853a80ca853b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Users of these tests speak of the 5 per cent. point [p-value of 5{\%}] in much the same way as I should speak of the K = 10 −1/2 point [e-value of 10 1/2 ], and of the 1 per cent. point [p-value of 1{\%}] as I should speak of the K = 10 −1 point [e-value of 10]. Abstract This note reanalyzes Cox's idealized example of testing with data splitting using e-values (Shafer's [8] betting scores). Cox's exciting finding was that the method of data splitting, while allowing flexible data analysis, achieves quite high efficiencies, of about 80{\%}. The most serious objection to the method was that it involves splitting data at random, and so different people analyzing the same data may get very different answers. Using e-values instead of p-values remedies this disadvantage.}
      \field{eprinttype}{arXiv}
      \field{title}{{A note on data splitting with e-values}}
      \field{year}{2020}
      \field{pages}{1\bibrangedash 11}
      \range{pages}{11}
      \verb{eprint}
      \verb arXiv:2008.11474v1
      \endverb
      \verb{file}
      \verb :Users/timbarry/research{\_}papers/e{\_}values{\_}splitting.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://alrw.net/e
      \endverb
      \verb{url}
      \verb http://alrw.net/e
      \endverb
    \endentry
    \entry{Vovk2021b}{article}{}
      \name{author}{2}{}{%
        {{uniquename=0,uniquepart=base,hash=bef6907ff5daebb69843cf35c8af1a83}{%
           family={Vovk},
           familyi={V\bibinitperiod},
           given={Vladimir},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=7ef1db76b008346b5aae55fe27c64483}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Ruodu},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{abdc3790d75ac8d5989a0755689bacfe}
      \strng{fullhash}{abdc3790d75ac8d5989a0755689bacfe}
      \strng{bibnamehash}{abdc3790d75ac8d5989a0755689bacfe}
      \strng{authorbibnamehash}{abdc3790d75ac8d5989a0755689bacfe}
      \strng{authornamehash}{abdc3790d75ac8d5989a0755689bacfe}
      \strng{authorfullhash}{abdc3790d75ac8d5989a0755689bacfe}
      \field{sortinit}{V}
      \field{sortinithash}{75dd7385c90b2252c3ae853a80ca853b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Multiple testing of a single hypothesis and testing multiple hypotheses are usually done in terms of p-values. In this paper, we replace p-values with their natural competitor, e-values, which are closely related to betting, Bayes factors and likelihood ratios. We demonstrate that e-values are often mathematically more tractable; in particular, in multiple testing of a single hypothesis, e-values can be merged simply by averaging them. This allows us to develop efficient procedures using e-values for testing multiple hypotheses.}
      \field{eprinttype}{arXiv}
      \field{issn}{21688966}
      \field{journaltitle}{Annals of Statistics}
      \field{number}{3}
      \field{title}{{E-values: Calibration, combination and applications}}
      \field{volume}{49}
      \field{year}{2021}
      \field{pages}{1736\bibrangedash 1754}
      \range{pages}{19}
      \verb{doi}
      \verb 10.1214/20-AOS2020
      \endverb
      \verb{eprint}
      \verb 1912.06116
      \endverb
      \verb{file}
      \verb :Users/timbarry/research{\_}papers/vovk{\_}wang{\_}2021.pdf:pdf
      \endverb
      \keyw{Admissible decisions,Bayes factor,Global null,Hypothesis testing,Multiple hypothesis testing,Test martingale}
    \endentry
    \entry{Wang2020b}{article}{}
      \name{author}{2}{}{%
        {{uniquename=0,uniquepart=base,hash=7ef1db76b008346b5aae55fe27c64483}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Ruodu},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=1397f973e97cb40b67654aac778db5ec}{%
           family={Ramdas},
           familyi={R\bibinitperiod},
           given={Aaditya},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{910d60adf8ccf9a11c4099de019528ef}
      \strng{fullhash}{910d60adf8ccf9a11c4099de019528ef}
      \strng{bibnamehash}{910d60adf8ccf9a11c4099de019528ef}
      \strng{authorbibnamehash}{910d60adf8ccf9a11c4099de019528ef}
      \strng{authornamehash}{910d60adf8ccf9a11c4099de019528ef}
      \strng{authorfullhash}{910d60adf8ccf9a11c4099de019528ef}
      \field{sortinit}{W}
      \field{sortinithash}{ecb89ff85896a47dc313960773ac311d}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{E-values have gained attention as potential alternatives to p-values as measures of uncertainty, significance and evidence. In brief, e-values are realized by random variables with expectation at most one under the null; examples include betting scores, (point null) Bayes factors, likelihood ratios and stopped supermartingales. We design a natural analog of the Benjamini-Hochberg (BH) procedure for false discovery rate (FDR) control that utilizes e-values, called the e-BH procedure, and compare it with the standard procedure for p-values. One of our central results is that, unlike the usual BH procedure, the e-BH procedure controls the FDR at the desired level---with no correction---for any dependence structure between the e-values. We illustrate that the new procedure is convenient in various settings of complicated dependence, structured and post-selection hypotheses, and multi-armed bandit problems. Moreover, the BH procedure is a special case of the e-BH procedure through calibration between p-values and e-values. Overall, the e-BH procedure is a novel, powerful and general tool for multiple testing under dependence, that is complementary to the BH procedure, each being an appropriate choice in different applications.}
      \field{eprinttype}{arXiv}
      \field{title}{{False discovery rate control with e-values}}
      \field{year}{2020}
      \field{pages}{1\bibrangedash 32}
      \range{pages}{32}
      \verb{eprint}
      \verb 2009.02824
      \endverb
      \verb{file}
      \verb :Users/timbarry/research{\_}papers/eBH.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2009.02824
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2009.02824
      \endverb
      \keyw{betting scores,fdr,multiple testing,p-values,supermartingales}
    \endentry
    \entry{Winkler2014}{article}{}
      \name{author}{5}{}{%
        {{uniquename=0,uniquepart=base,hash=c6d49384214266d0613d90ee6c950a07}{%
           family={Winkler},
           familyi={W\bibinitperiod},
           given={Anderson\bibnamedelima M.},
           giveni={A\bibinitperiod\bibinitdelim M\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=e2804769c994e6066e2b6d96704c6581}{%
           family={Ridgway},
           familyi={R\bibinitperiod},
           given={Gerard\bibnamedelima R.},
           giveni={G\bibinitperiod\bibinitdelim R\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=dc830bceb3451aab32e033c76d395623}{%
           family={Webster},
           familyi={W\bibinitperiod},
           given={Matthew\bibnamedelima A.},
           giveni={M\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=596f691dba28ef2442950b48293e1003}{%
           family={Smith},
           familyi={S\bibinitperiod},
           given={Stephen\bibnamedelima M.},
           giveni={S\bibinitperiod\bibinitdelim M\bibinitperiod},
           givenun=0}}%
        {{uniquename=0,uniquepart=base,hash=116f7b1002b0659693191921663276ae}{%
           family={Nichols},
           familyi={N\bibinitperiod},
           given={Thomas\bibnamedelima E.},
           giveni={T\bibinitperiod\bibinitdelim E\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {The Authors}%
      }
      \strng{namehash}{8b4846f269b7edc7d611dd75bf7afebd}
      \strng{fullhash}{f6d5fd2d1d81aca4e0a37ac557af5cbc}
      \strng{bibnamehash}{f6d5fd2d1d81aca4e0a37ac557af5cbc}
      \strng{authorbibnamehash}{f6d5fd2d1d81aca4e0a37ac557af5cbc}
      \strng{authornamehash}{8b4846f269b7edc7d611dd75bf7afebd}
      \strng{authorfullhash}{f6d5fd2d1d81aca4e0a37ac557af5cbc}
      \field{sortinit}{W}
      \field{sortinithash}{ecb89ff85896a47dc313960773ac311d}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Permutation methods can provide exact control of false positives and allow the use of non-standard statistics, making only weak assumptions about the data. With the availability of fast and inexpensive computing, their main limitation would be some lack of flexibility to work with arbitrary experimental designs. In this paper we report on results on approximate permutation methods that are more flexible with respect to the experimental design and nuisance variables, and conduct detailed simulations to identify the best method for settings that are typical for imaging research scenarios. We present a generic framework for permutation inference for complex general linear models (glms) when the errors are exchangeable and/or have a symmetric distribution, and show that, even in the presence of nuisance effects, these permutation inferences are powerful while providing excellent control of false positives in a wide range of common and relevant imaging research scenarios. We also demonstrate how the inference on glm parameters, originally intended for independent data, can be used in certain special but useful cases in which independence is violated. Detailed examples of common neuroimaging applications are provided, as well as a complete algorithm - the "randomise" algorithm - for permutation inference with the GLM. {©} 2014 The Authors.}
      \field{issn}{10959572}
      \field{journaltitle}{NeuroImage}
      \field{title}{{Permutation inference for the general linear model}}
      \field{volume}{92}
      \field{year}{2014}
      \field{pages}{381\bibrangedash 397}
      \range{pages}{17}
      \verb{doi}
      \verb 10.1016/j.neuroimage.2014.01.060
      \endverb
      \verb{file}
      \verb :Users/timbarry/research{\_}papers/Winkler2015.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://dx.doi.org/10.1016/j.neuroimage.2014.01.060
      \endverb
      \verb{url}
      \verb http://dx.doi.org/10.1016/j.neuroimage.2014.01.060
      \endverb
      \keyw{General linear model,Multiple regression,Permutation inference,Randomise}
    \endentry
  \enddatalist
\endrefsection
\endinput

